{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aeaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tweepy==4.10 yfinance scikit-learn pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84792317",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = \"INSERT_YOUR_BEARER_TOKEN_HERE\"  # üîê Replace with yours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tweepy\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6535c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower() \n",
    "    #text = re.sub(r'@[A-Za-z0-9_]+', '', text)  \n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)  # URL\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "    return text if text else \"empty\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ed045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"üß† Training sentiment model...\")\n",
    "\n",
    "# Download a small but clean dataset (Fake vs. Real News - classifiable text)\n",
    "!wget -q https://raw.githubusercontent.com/clairett/the-fake-news-challenge/master/data/train.csv -O train.csv\n",
    "\n",
    "# Leggi 2000 notizie \"fake\" (negative) e 2000 \"real\" (positive)\n",
    "df_fake = pd.read_csv('train.csv', usecols=[3], names=['text'], skiprows=1, nrows=2000)\n",
    "df_real = pd.read_csv('train.csv', usecols=[2], names=['text'], skiprows=1, nrows=2000)\n",
    "\n",
    "df_fake['label'] = 0  # fake ‚Üí negative\n",
    "df_real['label'] = 1  # real ‚Üí positive\n",
    "\n",
    "# Combine and mix\n",
    "df_full = pd.concat([df_fake, df_real]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Clean text\n",
    "df_full['clean_text'] = df_full['text'].apply(clean_text)\n",
    "\n",
    "# Remove empty line\n",
    "df_full = df_full[df_full['clean_text'] != \"empty\"]\n",
    "df_full = df_full[df_full['clean_text'].str.strip() != \"\"]\n",
    "\n",
    "print(f\"‚úÖ Training data ready: {len(df_full)} samples\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2), min_df=2)\n",
    "X = vectorizer.fit_transform(df_full['clean_text'])\n",
    "y = df_full['label']\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"‚úÖ Sentiment model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Tweets About Bitcoin (Last 7 Days)\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=True)\n",
    "\n",
    "seven_days_ago = datetime.now() - timedelta(days=7)\n",
    "query = \"bitcoin OR #bitcoin OR BTC OR $BTC lang:en\" \n",
    "\n",
    "tweets = client.search_recent_tweets(\n",
    "    query=query,\n",
    "    start_time=seven_days_ago,\n",
    "    max_results=100,\n",
    "    tweet_fields=['created_at'],\n",
    "    max_pages=3  # up to 300 tweets\n",
    ")\n",
    "\n",
    "# Saving data\n",
    "data = []\n",
    "for tweet in tweets:\n",
    "    if tweet.text:\n",
    "        data.append({\n",
    "            'date': tweet.created_at,\n",
    "            'text': tweet.text\n",
    "        })\n",
    "\n",
    "df_tweets = pd.DataFrame(data)\n",
    "if len(df_tweets) == 0:\n",
    "    raise ValueError(\"‚ùå No tweets collected. Check your query or Bearer Token.\")\n",
    "\n",
    "df_tweets['clean_text'] = df_tweets['text'].apply(clean_text)\n",
    "print(f\"‚úÖ Collected {len(df_tweets)} tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f89d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ANALYZE THE SENTIMENT OF TWEETS\n",
    "X_new = vectorizer.transform(df_tweets['clean_text'])\n",
    "sentiment = model.predict(X_new)\n",
    "confidence = model.predict_proba(X_new).max(axis=1)\n",
    "\n",
    "df_tweets['sentiment'] = sentiment  # 0=negative, 1=positive\n",
    "df_tweets['confidence'] = confidence\n",
    "df_tweets['date_only'] = pd.to_datetime(df_tweets['date']).dt.date\n",
    "\n",
    "# Daily Sentiment  (mean)\n",
    "daily_sentiment = df_tweets.groupby('date_only')['sentiment'].mean().reset_index()\n",
    "daily_sentiment['date_only'] = pd.to_datetime(daily_sentiment['date_only'])\n",
    "\n",
    "print(\"üìä Daily sentiment:\")\n",
    "print(daily_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Bitcoin price dowload\n",
    "print(\"üí∞ Downloading Bitcoin price...\")\n",
    "\n",
    "btc = yf.download(\"BTC-USD\", start=seven_days_ago, end=datetime.now())\n",
    "btc = btc[['Close']].reset_index()\n",
    "btc['date_only'] = pd.to_datetime(btc['Date']).dt.date\n",
    "btc.rename(columns={'Close': 'price'}, inplace=True)\n",
    "\n",
    "print(\"üìä Bitcoin price data:\")\n",
    "print(btc[['date_only', 'price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data and visualize\n",
    "merged = pd.merge(daily_sentiment, btc[['date_only', 'price']], on='date_only', how='inner')\n",
    "merged.rename(columns={'sentiment': 'sentiment_score'}, inplace=True)\n",
    "merged = merged.sort_values('date_only')\n",
    "\n",
    "if len(merged) == 0:\n",
    "    print(\"‚ùå No overlapping dates between tweets and price data.\")\n",
    "else:\n",
    "    print(\"üìà Final data for plotting:\")\n",
    "    print(merged)\n",
    "\n",
    "  \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    plt.plot(merged['date_only'], merged['price'], color='blue', label='Bitcoin Price (USD)')\n",
    "    plt.twinx().plot(merged['date_only'], merged['sentiment_score'], color='green', linestyle='--', label='Sentiment Score')\n",
    "    \n",
    "    plt.title('Bitcoin: Twitter Sentiment vs Price (Last 7 Days)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    lines, labels = plt.gca().get_legend_handles_labels()\n",
    "    lines2, labels2 = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend(lines + lines2[:1], labels + labels2[:1], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_corso (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
